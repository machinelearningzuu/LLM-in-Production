{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ragas, os\n",
    "import pandas as pd\n",
    "import os, nest_asyncio\n",
    "from datasets import Dataset\n",
    "os.chdir('/Users/1zuu/Library/Mobile Documents/com~apple~CloudDocs/ML DEV/LLM RESEARCH 2024/LLM in Production/01-diy-llm-qa-bot')\n",
    "nest_asyncio.apply() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Groq LLM ....\n",
      "Using HuggingFace Embedding ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/1zuu/miniforge3/envs/llamaindex/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/1zuu/miniforge3/envs/llamaindex/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.qabot_pipe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 16\n",
      "Loading Finance Index ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The eligibility criteria to open a Fixed Deposit include being a citizen of Sri Lanka above 18 years of age holding a valid National Identity Card (NIC), a valid Passport, or a Driving License. Additionally, Sri Lankan citizens residing temporarily outside Sri Lanka, individuals holding dual citizenship, and non-residents who possess a resident visa are also eligible.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qabot = QABot(llm=llm)\n",
    "qabot.get_answer(\"What are the Eligibility criteria to open a Fixed Deposit?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_response(question):\n",
    "    response = qabot.get_answer(question)\n",
    "    if response is None:\n",
    "        return \"\"\n",
    "    return response\n",
    "\n",
    "def load_eval_data():\n",
    "    df = pd.read_csv(path_config.eval_dataset_path)\n",
    "    df['response'] = df['question'].apply(make_response)\n",
    "\n",
    "    df = df.rename(columns={\n",
    "                            'context': 'contexts', \n",
    "                            'answer': 'ground_truth',\n",
    "                            'response': 'answer'\n",
    "                            })\n",
    "    df['contexts'] = df['contexts'].apply(lambda x: [x])\n",
    "    eval_data = Dataset.from_dict(df)\n",
    "    return eval_data\n",
    "\n",
    "def ragas_evaluate():\n",
    "    eval_data = load_eval_data()\n",
    "    result_json = ragas.evaluate(\n",
    "                                dataset=eval_data,\n",
    "                                metrics=[\n",
    "                                        ragas.metrics.faithfulness,\n",
    "                                        ragas.metrics.answer_relevancy,\n",
    "                                        ragas.metrics.context_precision,\n",
    "                                        ragas.metrics.context_recall\n",
    "                                        ]\n",
    "                            )\n",
    "    result_df = result_json.to_pandas()\n",
    "    result_df = result_df.fillna(0)\n",
    "    return result_df\n",
    "\n",
    "def evaluation_pipeline():\n",
    "    result_df = ragas_evaluate()\n",
    "    result_df.to_csv(path_config.eval_results_path, index=False)\n",
    "\n",
    "def calculate_avg_metrics():\n",
    "    if not os.path.exists(path_config.eval_results_path):\n",
    "        evaluation_pipeline()\n",
    "\n",
    "    result_df = pd.read_csv(path_config.eval_results_path)\n",
    "    result_df = result_df[[\n",
    "                        'faithfulness',\n",
    "                        'answer_relevancy',\n",
    "                        'context_precision',\n",
    "                        'context_recall'\n",
    "                        ]]\n",
    "    avg_metrics = result_df.mean()\n",
    "    return avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness         0.600000\n",
       "answer_relevancy     0.852696\n",
       "context_precision    1.000000\n",
       "context_recall       1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_avg_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
